from .BaseAgentExecutor import BaseAgentExecutor
from ...dependencies.parsers.intermediate.BaseIntermediateParser import BaseIntermediateParser


class ConversationalExecutor(BaseAgentExecutor):
    def __init__(self, agent, intermediate_parser: BaseIntermediateParser):
        """
        Initializes a ConversationalExecutor instance.

        Parameters:
        - agent (BaseAgent): The agent to be used in the loop.
        - intermediate_parser (BaseIntermediateParser): The parser for intermediate responses.
        """
        super().__init__(agent, intermediate_parser)

    async def run(self, prompt):
        """
        Executes the conversational agent based on the given prompt.

        Parameters:
        - prompt (str): The initial prompt to start the conversation.

        Returns:
        - str: The response generated by the conversational agent.
        """
        count = 0
        while True:
            # Limit API calls to 10
            if (count > 10):
                print(self.agent.llm.messages)
                return response
            count += 1
            response = self.agent.run(prompt)
            print(response)
            try:
                parsed = self.im_parser.parse_values(response)
                to_call = parsed[self.im_parser.tool_indicator]
                to_input = parsed[self.im_parser.input_indicator]

                if to_call.upper() == "RESPOND TO HUMAN":
                    print(self.agent.llm.messages)
                    return to_input

                else:
                    prompt = self.use_tool(response, to_call, to_input)

            except KeyError:
                self.agent.llm.add_messages(
                    [{"role": "system", "content": f'''Your attempted response: '{response}' didn't contain a JSON Blob. You must ALWAYS respond with a JSON blob. Reformat immediately. Remember to relay observations to the human. If you need clarification from the human, respond to the human'''}])
                continue
            except Exception as e:
                print(e)
                return response

    async def use_tool(self, response, to_call, to_input):
        """
        Utilizes a tool provided by the conversational agent based on the parsed values.

        Parameters:
        - response (str): The response from the conversational agent.
        - to_call (str): The name of the tool to be used.
        - to_input (dict or any): The input parameters for the tool.

        Returns:
        - str: The observation generated by using the tool.

        Raises:
        - ValueError: If the input format is invalid.
        - KeyError: If the tool cannot be found.
        """
        observation = None
        print(to_input, type(to_input))
        for tool in self.agent.tools:
            if to_call == tool.name:
                if isinstance(to_input, dict):
                    observation = tool.func(**to_input)
                    break
                elif isinstance(to_input, list):
                    raise ValueError(
                        "LLM produced list of parameters - invalid format must be dict or single value")
                else:
                    observation = tool.func(to_input)

        if (observation):
            self.agent.llm.add_messages(
                [{"role": "assistant", "content": response}])
            return f"Observation: {observation}"
        else:
            raise KeyError("No observation created - tool likely not found")
